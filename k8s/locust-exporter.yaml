apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: Service
metadata:
  name: locust-exporter
  namespace: monitoring
  labels:
    app: locust-exporter
spec:
  ports:
    - port: 9110
      targetPort: 9110
      protocol: TCP
      name: http
  selector:
    app: locust-exporter
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: locust-exporter
  namespace: monitoring
  labels:
    app: locust-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: locust-exporter
  template:
    metadata:
      labels:
        app: locust-exporter
    spec:
      containers:
        - name: locust-exporter
          image: python:3.11-slim
          command: ["/bin/sh", "-c"]
          args:
            - pip install --no-cache-dir -r /app/requirements.txt && python /app/app.py
          ports:
            - containerPort: 9110
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "200m"
              memory: "256Mi"
          volumeMounts:
            - name: app
              mountPath: /app
      volumes:
        - name: app
          configMap:
            name: locust-exporter-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: locust-exporter-config
  namespace: monitoring
  labels:
    app: locust-exporter
data:
  app.py: |
    from flask import Flask, Response
    import requests, time
    from bs4 import BeautifulSoup
    from prometheus_client import CollectorRegistry, Gauge, generate_latest, CONTENT_TYPE_LATEST

    # Service DNS used inside cluster
    LOCUST_STATS_URL = "http://locust-master.loadtest.svc.cluster.local:8089/stats/requests"
    SCRAPE_TIMEOUT = 5
    CACHE_TTL = 5.0

    app = Flask(__name__)
    _cache = {"ts": 0, "metrics": b""}

    def parse_number(s):
      if s is None:
        return 0.0
      s = s.replace(",", "").strip()
      try:
        return float(s)
      except Exception:
        return 0.0

    def collect():
      registry = CollectorRegistry()
      g_count = Gauge("locust_request_count", "Total requests", ["request", "method"], registry=registry)
      g_fail = Gauge("locust_request_failures", "Total failures", ["request", "method"], registry=registry)
      g_rps = Gauge("locust_request_rps", "Requests/sec (if provided)", ["request", "method"], registry=registry)
      g_avg = Gauge("locust_request_avg_ms", "Average request duration (ms)", ["request", "method"], registry=registry)
      try:
        r = requests.get(LOCUST_STATS_URL, timeout=SCRAPE_TIMEOUT)
        r.raise_for_status()
        parsed = None
        try:
          parsed = r.json()
        except Exception:
          parsed = None

        if isinstance(parsed, dict) and parsed.get("stats"):
          for stat in parsed.get("stats", []):
            name = stat.get("name") or stat.get("safe_name") or "unknown"
            method = stat.get("method") or "GET"
            total = float(stat.get("num_requests") or 0)
            failures = float(stat.get("num_failures") or 0)
            avg = float(stat.get("avg_response_time") or stat.get("avg") or 0)
            rps = float(stat.get("current_rps") or 0)
            g_count.labels(request=name, method=method).set(total)
            g_fail.labels(request=name, method=method).set(failures)
            g_avg.labels(request=name, method=method).set(avg)
            g_rps.labels(request=name, method=method).set(rps)
        else:
          soup = BeautifulSoup(r.text, "html.parser")
          tables = soup.find_all("table")
          target_table = None
          hdrs = []
          for t in tables:
            headers = [th.get_text(strip=True).lower() for th in t.find_all("th")]
            if "name" in headers and ("requests" in headers or "# requests" in headers):
              target_table = t
              hdrs = headers
              break
          if not target_table:
            return registry
          for row in target_table.find("tbody").find_all("tr"):
            cols = [td.get_text(strip=True) for td in row.find_all("td")]
            if len(cols) != len(hdrs):
              continue
            rowmap = dict(zip(hdrs, cols))
            name = rowmap.get("name") or rowmap.get("request") or "unknown"
            method = rowmap.get("method", "GET")
            total = parse_number(rowmap.get("requests") or rowmap.get("# requests") or "0")
            failures = parse_number(rowmap.get("failures") or rowmap.get("fail") or "0")
            avg = parse_number(rowmap.get("avg") or rowmap.get("average") or "0")
            rps = parse_number(rowmap.get("reqs/second") or rowmap.get("req/s") or rowmap.get("requests/s") or "0")
            g_count.labels(request=name, method=method).set(total)
            g_fail.labels(request=name, method=method).set(failures)
            g_avg.labels(request=name, method=method).set(avg)
            g_rps.labels(request=name, method=method).set(rps)
      except Exception:
        return registry
      return registry

    @app.route("/metrics")
    def metrics():
      now = time.time()
      if now - _cache["ts"] > CACHE_TTL:
        reg = collect()
        _cache["metrics"] = generate_latest(reg)
        _cache["ts"] = now
      return Response(_cache["metrics"], mimetype=CONTENT_TYPE_LATEST)

    if __name__ == "__main__":
      app.run(host="0.0.0.0", port=9110)
  requirements.txt: |
    flask
    requests
    beautifulsoup4
    prometheus_client
